import trimesh
import numpy as np
import requests
from PIL import Image
from transformers import BlipProcessor, BlipForConditionalGeneration
from glob import glob
from os import path, getcwd
from sentence_transformers import SentenceTransformer, util
from tqdm import tqdm
import argparse
import cv2
import csv
import os 

def cube():
    """
    Function that outputs the object rotations required to obtain the points of view 
    of our 3D object from the faces of a cube
    @return viewpoints : list [trimesh.transformations.rotation_matrix], list of rotation matrices
    from x axis, position (0,0,0).  """
    viewpoints = [
        trimesh.transformations.rotation_matrix(angle=np.pi/2, direction=[0, 1, 0]),
        trimesh.transformations.rotation_matrix(angle=np.pi, direction=[0, 1, 0]),
        trimesh.transformations.rotation_matrix(angle=-np.pi/2, direction=[0, 1, 0]),
        trimesh.transformations.rotation_matrix(angle=np.pi/2, direction=[1, 0, 0]),
        trimesh.transformations.rotation_matrix(angle=-np.pi/2, direction=[1, 0, 0]),
    ]
    return viewpoints

def sliced(n_images=100):
    """Function that outputs the object rotations required to obtain the points of view 
    of our 3D from a camera going around it.
    @param n_images : int, number of views
    @return viewpoints : list [trimesh.transformations.rotation_matrix] : list of rotation matrices
    from x axis, position (0,0,0)."""
    viewpoints = [
        trimesh.transformations.rotation_matrix(angle=2*i*np.pi/n_images, direction=[0.5, 0.5, 0])
        for i in range (n_images)
    ]
    return viewpoints

def icosahedron():
    """
    Function that outputs the object rotations required to obtain the points of view 
    of our 3D object from the vertices of an isochedron (the shape of a dice 20, with 12 vertices), 
    This means we no longer have a view from below or above, as was proposed with the
    the cube solution, since these are the views already generated by the Multi View model.
    we can truly assess the 3D model's ability to reconstitute new views
    without stable diffusion...
    @return viewpoints : list [trimesh.transformations.rotation_matrix] : list of rotation matrices
    from x axis, position (0,0,0).
    """    
    #vertices of our icosahedron
    phi = (1+np.sqrt(5))/2
    vertices = [[phi, 1, 0], [phi, -1, 0], [-phi, -1, 0], [-phi, 1, 0],
                [1, 0, phi], [-1, 0, phi], [-1, 0, -phi], [1, 0, -phi],
                [0, phi, 1], [0, phi, -1], [0, -phi, -1], [0, -phi, 1]]
    vertices = [np.array(e) for e in vertices]
    #vertices provided in the forum https://math.stackexchange.com/questions/2174594/co-ordinates-of-the-vertices-an-icosahedron-relative-to-its-centroid
    X = np.array([1,0,0]) #initial point of view
    O = np.array([0,0,0]) #center of the mesh
    viewpoints = []
    for e in vertices :
        XO = O - X
        YO = O - e
        XO = XO / np.linalg.norm(XO)
        YO = YO / np.linalg.norm(YO)
        angle  = np.arccos(np.clip(np.dot(XO, YO),-1,1))
        direction = np.cross(XO,YO)
        viewpoints.append(trimesh.transformations.rotation_matrix(angle=angle, direction=direction))
    return viewpoints

def screenshot_the_mesh(mesh, out_folder ='./imagesout_01/', method = icosahedron, save_views = False):
    """
    Script that takes screenshots from a trimesh mesh and that may save them
    @param mesh : trimesh mesh, mesh that we want to take screenshots from
    @param out_folder : str, where the images may be stored if saved
    @param method : python functiun, method used to take the screenshots
    @param save_views : Bool, argument that decides if we save the images taken at out_folder
    
    """
    resolution=(512, 384)
    filename_format="{:03d}.png"
    scene = trimesh.Scene()
    scene.add_geometry(mesh)
    # Create the output folder if it doesn't exist
    os.makedirs(out_folder, exist_ok=True)
    # Let's consider the method chosen to take screenshots
    viewpoints = method()
    screenshots = [] #possible improvement, consider a generator ????
    for i, viewpoint in enumerate(viewpoints):
        # move the camera
        camera_old, _ = scene.graph[scene.camera.name]
        scene.graph[scene.camera.name] = np.dot(viewpoint, camera_old)
        filename = filename_format.format(i)
        try :
            png = scene.save_image(resolution=resolution, visible=True)
            img_arr = cv2.imdecode(np.fromstring(png, np.uint8), cv2.IMREAD_COLOR)
            rgb_img = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB) 
            screenshots.append(rgb_img)
            # save the images if needed?
            if save_views :
                with open(path.join(out_folder,filename), "wb") as f:
                    f.write(png)
            # start again from initial view
            scene.graph[scene.camera.name] = camera_old
        except ZeroDivisionError:
            print("Error: Window resizing caused division by zero. Try setting minimum window size or handling resizing events.")
    return screenshots

def prompts_the_views(processor, model, screenshots):
    """
    method to prompt the views of our images generated
    @param processor : processor of the model model
    @param model: model, image-to-text model
    @param screenshots : list[PIL.Image], list of images to prompt
    @return Prompts : list[Str], list of prompts that describe the images
    """
    Prompts = []
    for raw_image in screenshots:
        inputs = processor(raw_image, return_tensors="pt")
        out = model.generate(**inputs)
        Prompts.append(processor.decode(out[0], skip_special_tokens=True))
    return Prompts


def compare_two_prompts(prompt, prompts, model_comparation, show_scores = True):
    """
    method that compute the distance between one prompt and a list of prompts
    @param prompt :str, prompt entered to the prompt-to-3D model
    @param prompts : list[str], prompts that describe the views of the 3D asset
    @param model_comparation : model, model that encodes the prompts
    @param show_scores : Bool, show or not the scores.
    @return mean_score : float, average score of the 3D asset generated
    """
    #prompt entered to geerate the 3D asset
    prompt_embedded = model_comparation.encode(prompt)
    #list of prompts generated from all the images
    prompts_embedded = model_comparation.encode(prompts)
    #distance between the original prompt and the prompts from the views
    scores = util.dot_score(prompt_embedded, prompts_embedded)[0].cpu().tolist()
    if show_scores :
        doc_score_pairs = list(zip(prompts, scores))
        #allows to sort the list according to the scores
        #doc_score_pairs = sorted(doc_score_pairs, key=lambda x: x[1], reverse=True)
        for doc, score in doc_score_pairs:
            print(score, doc)
    mean_score = sum(scores)/len(scores)
    return mean_score

def main(method, folder_mother, name, save_views):
    """
    Script to automate an evaluation of the 3D assets generated
    it stores everything in a csv, it prints the average score
    @param method : pyhton functiun, method to take the views from the 3D asset
    @param folder_mother : str, folder where are stored the 3D assets
    @param name : name of the mesh (if not entered will consider any mesh found at the location of the script)
    @param save_views :Bool, save or not the screenshots

    """
    os.environ['DISPLAY'] = ':0.0'
    ##Load the models that will be used
    #First the image to prompt model 
    processor = BlipProcessor.from_pretrained("Salesforce/blip-image-captioning-base")
    model = BlipForConditionalGeneration.from_pretrained("Salesforce/blip-image-captioning-base")
    #load the model that will compare the prompts
    model_comparation = SentenceTransformer('sentence-transformers/msmarco-distilbert-cos-v5')
    cwd = getcwd()
    folder_mother = path.relpath(folder_mother, cwd)
    #load the prompts
    with open(path.join(folder_mother, 'prompts.txt'), 'r') as f:
        prompts = [line.strip()[:] for line in f.readlines()]
    #loop on each asset
    scores = []
    for n_prompt,folder in enumerate(tqdm(sorted(glob(path.join(folder_mother, '[0-9]*/'))))):
        folder_name = path.relpath(folder, cwd)
        #manipulation of the 3D asset considering the name of the mesh
        if name:
            asset_path = path.join(folder_name, name) 
            if not path.isfile(asset_path):
                raise FileNotFoundError(f"Le dossier '{folder_name}' est incomplet, il devrait contenir : '{name}.obj'")
            name_csv = '/' + name + '_scores.csv'
            out_message = f', pour le model {name}'
        else:
            asset_path = glob(path.join(folder, "*.obj"))
            if len(asset_path!=1):
                raise FileNotFoundError(f"Le dossier '{folder_name}' contient plus d'un fichier .obj, il ne doit en contenir qu'un seul exactement")
            name_csv = '/scores.csv'
            out_message = ''
        mesh = trimesh.load(asset_path)
        screenshots = screenshot_the_mesh(mesh = mesh, out_folder = folder, method = method, save_views = save_views)
        prompts_created = prompts_the_views(processor = processor, model = model, screenshots = screenshots)
        prompt_main = prompts[n_prompt]
        score = compare_two_prompts(prompt_main,prompts_created, model_comparation)
        scores.append(score)
        #stores the results per asset in a csv
        with open(folder_mother + name_csv, "a", newline="") as csvfile:
            writer = csv.writer(csvfile)
            writer.writerow([n_prompt, score, prompts[n_prompt] ])
    out_message = f"le score moyen que nous venons de calculer est de {np.mean(scores)}" + out_message
    print(out_message)

if __name__== "__main__" :
    parser = argparse.ArgumentParser(description = 'Evaluer les performances de mes assets 3D')
    parser.add_argument(
        "--method",
        help = "vues prises, que ce soit celles d'un icosahedron (12 sommets) ou d'un cube (6 faces)...",
        default = icosahedron
    )
    parser.add_argument(
        "--folder_mother",
        help = "fichier dans lequel sont situees les mesh de nos objets 3D",
        default = './',
        type = str
    )
    parser.add_argument(
        "--name",
        help = "nom des fichiers .obj",
        default = None,
        type = str
    )
    parser.add_argument(
        "--save_views",
        default = False,
        type = bool,
        help = "booléen qui décide si oui ou non on sauvegarde les vues de notre modèle"
    )
    args = parser.parse_args()
    main(**vars(args))